{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "brandbankExtract = r'C:\\Users\\admin_1878\\Documents\\Brandbank Data\\Extracted Data\\Brandbank Extract.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(brandbankExtract)\n",
    "df=df.fillna('')\n",
    "df['text'] = df[[\n",
    "    'description',\n",
    "    'allergyAdvice',\n",
    "    'recycling',\n",
    "    'recycling_other',\n",
    "    'brands',\n",
    "    'marketing',\n",
    "    'ingredients',\n",
    "    'features',\n",
    "    'storage',\n",
    "    'preserves']].agg(' '.join, axis=1)\n",
    "df=df.drop(['name'\n",
    "    ,'pl2','pl3',\n",
    "    'description',\n",
    "    'allergyAdvice',\n",
    "    'recycling',\n",
    "    'recycling_other',\n",
    "    'brands',\n",
    "    'marketing',\n",
    "    'ingredients',\n",
    "    'features',\n",
    "    'storage',\n",
    "    'preserves'],axis=1)\n",
    "df.rename({'pl1':'category'},axis=1, inplace=True)\n",
    "df.drop(df[df['category'] =='Kruidenierswaren'].index, inplace=True)#onyl 1 example of this so dropping for simplicity\n",
    "df['category'] = df['category'].str.replace(\" \", \"_\")\n",
    "df = df[df['category'] != '']\n",
    "df = df[df['category'] != 'Unallocated']\n",
    "df['text'] = df['text'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAKE_NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords') #Only needs to be run once to download stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_words(row):\n",
    "    return len(str(row['Phrase']).split())\n",
    "\n",
    "def get_perc_phrase(row,total):\n",
    "    return (float(row['Score'])/total*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Rake_phrases(df):\n",
    "    r = Rake()\n",
    "    r.extract_keywords_from_sentences(df['text'])\n",
    "    phrases=r.get_ranked_phrases_with_scores()\n",
    "    df = pd.DataFrame(phrases, columns = ['Rank', 'Phrase'])\n",
    "    df['Phrase'] = df['Phrase'].str.strip()\n",
    "    phrase_counts = df['Phrase'].value_counts()\n",
    "    phrase_counts = phrase_counts.reset_index()\n",
    "    phrase_counts.columns=['Phrase','Score']\n",
    "    phrase_counts['Length'] = phrase_counts.apply (lambda row: get_num_words(row), axis=1)\n",
    "    phrase_counts=phrase_counts.loc[phrase_counts['Length'] <=6]\n",
    "    total = float(phrase_counts['Score'].sum())\n",
    "    phrase_counts['Perc'] = phrase_counts.apply (lambda row: get_perc_phrase(row,total), axis=1)\n",
    "    return phrase_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raked = get_Rake_phrases(df)\n",
    "#phrase_counts.to_csv(r'C:\\Users\\Clamfighter\\Documents\\GitHub\\NLP\\Impact Score Key Phrase\\Extracted Phrases\\Rake NLTK\\Brandbank Latest Phrase Extraction.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_count=[]\n",
    "\n",
    "df_phraseCount = df_raked.loc[df_raked['Score'] != 1] #filters Score of 1 out. will be added back in later\n",
    "phrases = df_phraseCount['Phrase']\n",
    "text = df['text']\n",
    "for phrase in phrases: #find number of phrases for all strings\n",
    "    phrase_count.append(sum(phrase in s for s in text))\n",
    "    print (phrase)\n",
    "phrase_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phraseCount['Count'] = phrase_count\n",
    "df_phraseCount.drop(['Score','Length','Perc'],axis=1, inplace=True)\n",
    "df_out = df_raked.merge(df_phraseCount, on='Phrase', how='left')\n",
    "df_out.fillna(1,inplace=True)\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv(r'out_lower.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
